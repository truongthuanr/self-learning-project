{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_QA_ChatBot.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/truongthuanr/self-project/blob/main/06_QA_ChatBot.ipynb",
      "authorship_tag": "ABX9TyMMsJuxNI3Vt/Qla1cmvPBl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/truongthuanr/self-project/blob/main/06_QA_ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmqEJ03IWNW6"
      },
      "source": [
        "# Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26q629jLUKIr"
      },
      "source": [
        "Reference: \n",
        "* [End-To-End Memory Networks](https://arxiv.org/pdf/1503.08895.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1Ie4ox6WO1C"
      },
      "source": [
        "# import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbZ3fB8Eze0q"
      },
      "source": [
        "import numpy as np\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvLzr8HZy1oO"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/01_Personal/01_Study/01_ML/04_QAChatBot/train_qa.txt\", \"rb\") as f:\n",
        "  train_data = pickle.load(f)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/01_Personal/01_Study/01_ML/04_QAChatBot/test_qa.txt\", \"rb\") as f:\n",
        "  test_data = pickle.load(f)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGdecLspH5Dg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f2dfa3-1a3c-40b4-eba0-4183fb7bcf24"
      },
      "source": [
        "print(train_data[506][0])\n",
        "print(train_data[506][1])\n",
        "print(train_data[506][2])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Daniel', 'took', 'the', 'milk', 'there', '.', 'Sandra', 'journeyed', 'to', 'the', 'bedroom', '.', 'Daniel', 'discarded', 'the', 'milk', '.', 'Mary', 'went', 'to', 'the', 'bathroom', '.']\n",
            "['Is', 'Mary', 'in', 'the', 'bathroom', '?']\n",
            "yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MtCkceaGfSl"
      },
      "source": [
        "all_data = train_data + test_data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF42gtM0zbNb",
        "outputId": "603cb383-1574-48c1-8b24-9c7392ff5519"
      },
      "source": [
        "len(train_data), len(test_data), len(all_data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1000, 11000)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyZ8yMJdFvIr"
      },
      "source": [
        "vocab = set()\n",
        "\n",
        "for story, question, answer in all_data:\n",
        "  vocab = vocab.union(set(story))\n",
        "  vocab = vocab.union(set(question))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0G5eNaXHb9S"
      },
      "source": [
        "vocab.add('no')\n",
        "vocab.add('yes')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RZVspeHHnnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5acee8de-7d8f-4191-eb6f-1be944ce89fa"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH8_3aSYLPck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0293d432-e4ba-45bc-ef17-4cb902c7b304"
      },
      "source": [
        "vocab"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWxdyf9UHo0C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c1b0afe-9432-4e6a-dfa2-06f4e9576aaf"
      },
      "source": [
        "all_story_lens = [len(data[0]) for data in all_data]\n",
        "max_story_len = max(all_story_lens)\n",
        "max_story_len"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AWrOI-iIzhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa2e9171-f1e9-460a-c828-62dd18ecd333"
      },
      "source": [
        "all_ques_lens = [len(data[1]) for data in all_data]\n",
        "max_ques_len = max(all_ques_lens)\n",
        "max_ques_len"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4qAJZ3NJDm_"
      },
      "source": [
        "# Vetorize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ikI4FAtJIPr"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI3DQuvKJg6M"
      },
      "source": [
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlsSrdl7JpGV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dd74c71-f074-42c7-e7c2-69c8a79e5850"
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 15,\n",
              " '?': 34,\n",
              " 'apple': 37,\n",
              " 'back': 9,\n",
              " 'bathroom': 35,\n",
              " 'bedroom': 13,\n",
              " 'daniel': 8,\n",
              " 'discarded': 31,\n",
              " 'down': 14,\n",
              " 'dropped': 25,\n",
              " 'football': 6,\n",
              " 'garden': 3,\n",
              " 'got': 18,\n",
              " 'grabbed': 7,\n",
              " 'hallway': 10,\n",
              " 'in': 28,\n",
              " 'is': 23,\n",
              " 'john': 4,\n",
              " 'journeyed': 17,\n",
              " 'kitchen': 27,\n",
              " 'left': 5,\n",
              " 'mary': 36,\n",
              " 'milk': 20,\n",
              " 'moved': 1,\n",
              " 'no': 33,\n",
              " 'office': 12,\n",
              " 'picked': 30,\n",
              " 'put': 24,\n",
              " 'sandra': 21,\n",
              " 'the': 22,\n",
              " 'there': 29,\n",
              " 'to': 16,\n",
              " 'took': 19,\n",
              " 'travelled': 2,\n",
              " 'up': 32,\n",
              " 'went': 26,\n",
              " 'yes': 11}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t858S3jpKAin"
      },
      "source": [
        "train_story_text = []\n",
        "train_ques_text = []\n",
        "train_ans_text = []"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1vF5Wd6KHul"
      },
      "source": [
        "for story,ques,ans in train_data:\n",
        "  train_story_text.append(story)\n",
        "  train_ques_text.append(ques)\n",
        "  train_ans_text.append(ans)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhgKoQ9xKzCq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52daa2ce-680e-450a-c902-0924480fd332"
      },
      "source": [
        "train_story_text[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mary',\n",
              " 'moved',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bathroom',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'journeyed',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bedroom',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3_Kk60JKX85"
      },
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxGBRD0NK-pd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7728b11a-1992-485d-db35-f4a330e74f2f"
      },
      "source": [
        "len(train_story_seq)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJe53E24KwnL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8b75fb4-b545-4d30-c2b7-301603d1e3f3"
      },
      "source": [
        "train_story_seq[0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[36, 1, 16, 22, 35, 15, 21, 17, 16, 22, 13, 15]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxIOp5PYnxF3"
      },
      "source": [
        "# Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gW4dCkMKylP"
      },
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_ques_len):\n",
        "  '''\n",
        "  INPUT: \n",
        "  \n",
        "  data: consisting of Stories,Queries,and Answers\n",
        "  word_index: word index dictionary from tokenizer\n",
        "  max_story_len: the length of the longest story (used for pad_sequences function)\n",
        "  max_question_len: length of the longest question (used for pad_sequences function)\n",
        "\n",
        "\n",
        "  OUTPUT:\n",
        "  \n",
        "  Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
        "  answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
        "  output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
        "  \n",
        "  Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
        "  '''\n",
        "  \n",
        "  \n",
        "  # X = STORIES\n",
        "  X = []\n",
        "  # Xq = QUERY/QUESTION\n",
        "  Xq = []\n",
        "  # Y = CORRECT ANSWER\n",
        "  Y = []\n",
        "  \n",
        "  \n",
        "  for story, query, answer in data:\n",
        "      \n",
        "      # Grab the word index for every word in story\n",
        "      x = [word_index[word.lower()] for word in story]\n",
        "      # Grab the word index for every word in query\n",
        "      xq = [word_index[word.lower()] for word in query]\n",
        "      \n",
        "      # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
        "      # Index 0 is reserved so we're going to use + 1\n",
        "      y = np.zeros(len(word_index) + 1)\n",
        "      \n",
        "      # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
        "      #\n",
        "      y[word_index[answer]] = 1\n",
        "      \n",
        "      # Append each set of story,query, and answer to their respective holding lists\n",
        "      X.append(x)\n",
        "      Xq.append(xq)\n",
        "      Y.append(y)\n",
        "      \n",
        "  # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
        "      \n",
        "  # RETURN TUPLE FOR UNPACKING\n",
        "  return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFNF5hAanpHJ"
      },
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAyTv0hlGN6u"
      },
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-ApQ8LfGkPT",
        "outputId": "6e148fc5-a929-4a82-e989-82b9df7866b7"
      },
      "source": [
        "inputs_test[0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0, 36, 18, 22, 20, 29, 15,  4,  1, 16,\n",
              "       22, 13, 15], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_eTX9BhG-iH",
        "outputId": "9e83e372-02b9-4253-eaa3-49b0276719d7"
      },
      "source": [
        "inputs_train"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 22, 13, 15],\n",
              "       [ 0,  0,  0, ..., 22, 10, 15],\n",
              "       [ 0,  0,  0, ..., 22, 35, 15],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 22, 13, 15],\n",
              "       [ 0,  0,  0, ..., 20, 29, 15],\n",
              "       [ 0,  0,  0, ..., 37, 29, 15]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgd0Lo6HI6Lw",
        "outputId": "3186d7ab-98c8-45cd-dbb7-b9e14c3f118d"
      },
      "source": [
        "inputs_train.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 156)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3emtR1SH2Zw",
        "outputId": "0013c1ee-6cb0-4822-e2ed-cddb87d86e2c"
      },
      "source": [
        "answers_test"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsmeNfUxH3bB",
        "outputId": "c45eadbc-b774-4330-90be-ce2b9a013019"
      },
      "source": [
        "answers_test.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoKbiTaYJAAq"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from keras.layers import add, dot, concatenate\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQZI5ud9JvPU"
      },
      "source": [
        "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs7W9_VEKBzN"
      },
      "source": [
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_ques_len,))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TG4P1MQKEgN"
      },
      "source": [
        "vocab_size = len(vocab) + 1"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WmuKrVyJG5p"
      },
      "source": [
        "### Input Encorder m"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRJyHJA5NtPF"
      },
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAFcFmV2Nz-t"
      },
      "source": [
        "### Input Encorder c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DkGhGlBN5C4"
      },
      "source": [
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_ques_len))\n",
        "input_encoder_c.add(Dropout(0.3))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss5Cb7v3MjYD"
      },
      "source": [
        "### Question encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lka6Iv7BMn5j"
      },
      "source": [
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=64,\n",
        "                               input_length=max_ques_len))\n",
        "question_encoder.add(Dropout(0.3))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEDs_ny-MrPF"
      },
      "source": [
        "### Encode the Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBcJITxXM69g"
      },
      "source": [
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mS0YGFCNN_S"
      },
      "source": [
        "Use dot product to compute the match between first input vector seq and the query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OcSkFVENOiD"
      },
      "source": [
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3izT28pXNT3s"
      },
      "source": [
        "Add this match matrix with the second input vector sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuj8Uk8WNWIm"
      },
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjqt0BvaNYio"
      },
      "source": [
        "Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPKfhYMuNeQ3"
      },
      "source": [
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6YifltkNfMS",
        "outputId": "e5b93980-ff22-4d25-b4ca-b61404d08de4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "answer"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otw70R_xNgzz"
      },
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)  # (samples, 32)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fkp8S_fLNj8x"
      },
      "source": [
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTJwSon_Nlur"
      },
      "source": [
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW8oKDtWNoMi",
        "outputId": "b62defbd-844b-4f4e-c090-95d5c364193e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 156)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, None, 64)     2432        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 156, 6)       0           sequential[0][0]                 \n",
            "                                                                 sequential_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 156, 6)       0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, None, 6)      228         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 156, 6)       0           activation[0][0]                 \n",
            "                                                                 sequential_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute (Permute)               (None, 6, 156)       0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 6, 220)       0           permute[0][0]                    \n",
            "                                                                 sequential_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 32)           32384       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32)           0           lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 38)           1254        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 38)           0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLYpZgChNpku",
        "outputId": "141a6d4a-15fa-478f-ec4b-0e920a7b28f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# train\n",
        "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "313/313 [==============================] - 8s 17ms/step - loss: 0.9246 - accuracy: 0.4911 - val_loss: 0.6968 - val_accuracy: 0.5030\n",
            "Epoch 2/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.7050 - accuracy: 0.4993 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 3/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6959 - accuracy: 0.5032 - val_loss: 0.6932 - val_accuracy: 0.4910\n",
            "Epoch 4/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6949 - accuracy: 0.4974 - val_loss: 0.6956 - val_accuracy: 0.5030\n",
            "Epoch 5/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6948 - accuracy: 0.4936 - val_loss: 0.6938 - val_accuracy: 0.4970\n",
            "Epoch 6/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6948 - accuracy: 0.5019 - val_loss: 0.6941 - val_accuracy: 0.5030\n",
            "Epoch 7/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6948 - accuracy: 0.4883 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
            "Epoch 8/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6942 - accuracy: 0.4950 - val_loss: 0.6950 - val_accuracy: 0.4970\n",
            "Epoch 9/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6947 - accuracy: 0.4971 - val_loss: 0.6937 - val_accuracy: 0.5030\n",
            "Epoch 10/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6939 - accuracy: 0.5049 - val_loss: 0.6937 - val_accuracy: 0.4660\n",
            "Epoch 11/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6938 - accuracy: 0.5026 - val_loss: 0.6944 - val_accuracy: 0.4850\n",
            "Epoch 12/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6931 - accuracy: 0.5139 - val_loss: 0.6949 - val_accuracy: 0.4830\n",
            "Epoch 13/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6892 - accuracy: 0.5251 - val_loss: 0.6895 - val_accuracy: 0.5130\n",
            "Epoch 14/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6694 - accuracy: 0.5762 - val_loss: 0.6520 - val_accuracy: 0.6290\n",
            "Epoch 15/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6301 - accuracy: 0.6458 - val_loss: 0.6123 - val_accuracy: 0.6670\n",
            "Epoch 16/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6126 - accuracy: 0.6656 - val_loss: 0.5876 - val_accuracy: 0.6870\n",
            "Epoch 17/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5912 - accuracy: 0.6857 - val_loss: 0.5650 - val_accuracy: 0.6970\n",
            "Epoch 18/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5606 - accuracy: 0.7182 - val_loss: 0.5140 - val_accuracy: 0.7620\n",
            "Epoch 19/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5338 - accuracy: 0.7434 - val_loss: 0.4836 - val_accuracy: 0.7790\n",
            "Epoch 20/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5017 - accuracy: 0.7684 - val_loss: 0.4597 - val_accuracy: 0.7860\n",
            "Epoch 21/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4771 - accuracy: 0.7834 - val_loss: 0.4424 - val_accuracy: 0.8000\n",
            "Epoch 22/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4600 - accuracy: 0.7965 - val_loss: 0.4340 - val_accuracy: 0.8160\n",
            "Epoch 23/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4409 - accuracy: 0.8109 - val_loss: 0.4263 - val_accuracy: 0.8300\n",
            "Epoch 24/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4258 - accuracy: 0.8189 - val_loss: 0.4255 - val_accuracy: 0.8250\n",
            "Epoch 25/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4063 - accuracy: 0.8279 - val_loss: 0.3872 - val_accuracy: 0.8310\n",
            "Epoch 26/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4035 - accuracy: 0.8279 - val_loss: 0.4108 - val_accuracy: 0.8150\n",
            "Epoch 27/120\n",
            "313/313 [==============================] - 5s 14ms/step - loss: 0.3859 - accuracy: 0.8393 - val_loss: 0.3900 - val_accuracy: 0.8450\n",
            "Epoch 28/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3783 - accuracy: 0.8376 - val_loss: 0.3787 - val_accuracy: 0.8340\n",
            "Epoch 29/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3711 - accuracy: 0.8461 - val_loss: 0.3695 - val_accuracy: 0.8380\n",
            "Epoch 30/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3616 - accuracy: 0.8506 - val_loss: 0.3680 - val_accuracy: 0.8300\n",
            "Epoch 31/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3535 - accuracy: 0.8524 - val_loss: 0.3522 - val_accuracy: 0.8350\n",
            "Epoch 32/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3462 - accuracy: 0.8542 - val_loss: 0.3741 - val_accuracy: 0.8270\n",
            "Epoch 33/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3402 - accuracy: 0.8552 - val_loss: 0.3485 - val_accuracy: 0.8450\n",
            "Epoch 34/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3331 - accuracy: 0.8594 - val_loss: 0.3608 - val_accuracy: 0.8270\n",
            "Epoch 35/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3307 - accuracy: 0.8594 - val_loss: 0.3778 - val_accuracy: 0.8300\n",
            "Epoch 36/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3288 - accuracy: 0.8604 - val_loss: 0.3573 - val_accuracy: 0.8400\n",
            "Epoch 37/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3190 - accuracy: 0.8646 - val_loss: 0.3489 - val_accuracy: 0.8370\n",
            "Epoch 38/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3164 - accuracy: 0.8643 - val_loss: 0.3691 - val_accuracy: 0.8360\n",
            "Epoch 39/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3196 - accuracy: 0.8620 - val_loss: 0.3649 - val_accuracy: 0.8230\n",
            "Epoch 40/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3102 - accuracy: 0.8662 - val_loss: 0.3674 - val_accuracy: 0.8340\n",
            "Epoch 41/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3119 - accuracy: 0.8646 - val_loss: 0.3593 - val_accuracy: 0.8250\n",
            "Epoch 42/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3057 - accuracy: 0.8688 - val_loss: 0.3742 - val_accuracy: 0.8250\n",
            "Epoch 43/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3024 - accuracy: 0.8682 - val_loss: 0.3741 - val_accuracy: 0.8240\n",
            "Epoch 44/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3031 - accuracy: 0.8696 - val_loss: 0.3422 - val_accuracy: 0.8440\n",
            "Epoch 45/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2973 - accuracy: 0.8680 - val_loss: 0.3483 - val_accuracy: 0.8270\n",
            "Epoch 46/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2927 - accuracy: 0.8691 - val_loss: 0.3536 - val_accuracy: 0.8430\n",
            "Epoch 47/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2908 - accuracy: 0.8749 - val_loss: 0.3739 - val_accuracy: 0.8290\n",
            "Epoch 48/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2908 - accuracy: 0.8735 - val_loss: 0.3527 - val_accuracy: 0.8330\n",
            "Epoch 49/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2869 - accuracy: 0.8734 - val_loss: 0.3748 - val_accuracy: 0.8350\n",
            "Epoch 50/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2869 - accuracy: 0.8740 - val_loss: 0.3628 - val_accuracy: 0.8270\n",
            "Epoch 51/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2824 - accuracy: 0.8768 - val_loss: 0.3683 - val_accuracy: 0.8290\n",
            "Epoch 52/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2858 - accuracy: 0.8719 - val_loss: 0.3724 - val_accuracy: 0.8270\n",
            "Epoch 53/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2801 - accuracy: 0.8773 - val_loss: 0.3747 - val_accuracy: 0.8280\n",
            "Epoch 54/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2802 - accuracy: 0.8784 - val_loss: 0.3628 - val_accuracy: 0.8400\n",
            "Epoch 55/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2813 - accuracy: 0.8762 - val_loss: 0.3557 - val_accuracy: 0.8310\n",
            "Epoch 56/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2724 - accuracy: 0.8812 - val_loss: 0.3838 - val_accuracy: 0.8250\n",
            "Epoch 57/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2770 - accuracy: 0.8803 - val_loss: 0.3631 - val_accuracy: 0.8380\n",
            "Epoch 58/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2798 - accuracy: 0.8751 - val_loss: 0.3641 - val_accuracy: 0.8330\n",
            "Epoch 59/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2755 - accuracy: 0.8792 - val_loss: 0.4142 - val_accuracy: 0.8290\n",
            "Epoch 60/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2678 - accuracy: 0.8803 - val_loss: 0.3944 - val_accuracy: 0.8350\n",
            "Epoch 61/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2718 - accuracy: 0.8793 - val_loss: 0.3612 - val_accuracy: 0.8290\n",
            "Epoch 62/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2672 - accuracy: 0.8827 - val_loss: 0.4026 - val_accuracy: 0.8290\n",
            "Epoch 63/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2688 - accuracy: 0.8824 - val_loss: 0.3760 - val_accuracy: 0.8290\n",
            "Epoch 64/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2692 - accuracy: 0.8811 - val_loss: 0.4287 - val_accuracy: 0.8210\n",
            "Epoch 65/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2678 - accuracy: 0.8831 - val_loss: 0.3746 - val_accuracy: 0.8340\n",
            "Epoch 66/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2640 - accuracy: 0.8847 - val_loss: 0.4001 - val_accuracy: 0.8280\n",
            "Epoch 67/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2620 - accuracy: 0.8848 - val_loss: 0.3798 - val_accuracy: 0.8360\n",
            "Epoch 68/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2558 - accuracy: 0.8859 - val_loss: 0.3846 - val_accuracy: 0.8330\n",
            "Epoch 69/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2611 - accuracy: 0.8869 - val_loss: 0.3812 - val_accuracy: 0.8340\n",
            "Epoch 70/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2609 - accuracy: 0.8876 - val_loss: 0.3910 - val_accuracy: 0.8290\n",
            "Epoch 71/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2642 - accuracy: 0.8847 - val_loss: 0.3809 - val_accuracy: 0.8300\n",
            "Epoch 72/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2618 - accuracy: 0.8864 - val_loss: 0.3672 - val_accuracy: 0.8320\n",
            "Epoch 73/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2586 - accuracy: 0.8879 - val_loss: 0.3732 - val_accuracy: 0.8280\n",
            "Epoch 74/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2554 - accuracy: 0.8879 - val_loss: 0.3877 - val_accuracy: 0.8330\n",
            "Epoch 75/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2523 - accuracy: 0.8880 - val_loss: 0.3949 - val_accuracy: 0.8320\n",
            "Epoch 76/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2538 - accuracy: 0.8898 - val_loss: 0.3721 - val_accuracy: 0.8270\n",
            "Epoch 77/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2481 - accuracy: 0.8890 - val_loss: 0.3863 - val_accuracy: 0.8290\n",
            "Epoch 78/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2492 - accuracy: 0.8921 - val_loss: 0.4029 - val_accuracy: 0.8340\n",
            "Epoch 79/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2536 - accuracy: 0.8887 - val_loss: 0.4037 - val_accuracy: 0.8300\n",
            "Epoch 80/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2470 - accuracy: 0.8900 - val_loss: 0.3726 - val_accuracy: 0.8270\n",
            "Epoch 81/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2470 - accuracy: 0.8913 - val_loss: 0.3909 - val_accuracy: 0.8370\n",
            "Epoch 82/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2431 - accuracy: 0.8935 - val_loss: 0.3813 - val_accuracy: 0.8360\n",
            "Epoch 83/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2424 - accuracy: 0.8956 - val_loss: 0.3894 - val_accuracy: 0.8300\n",
            "Epoch 84/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2427 - accuracy: 0.8922 - val_loss: 0.4050 - val_accuracy: 0.8280\n",
            "Epoch 85/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2451 - accuracy: 0.8942 - val_loss: 0.4345 - val_accuracy: 0.8270\n",
            "Epoch 86/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2328 - accuracy: 0.9002 - val_loss: 0.4147 - val_accuracy: 0.8300\n",
            "Epoch 87/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2411 - accuracy: 0.8941 - val_loss: 0.3938 - val_accuracy: 0.8260\n",
            "Epoch 88/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2396 - accuracy: 0.8933 - val_loss: 0.3911 - val_accuracy: 0.8370\n",
            "Epoch 89/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2324 - accuracy: 0.8983 - val_loss: 0.4080 - val_accuracy: 0.8300\n",
            "Epoch 90/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2327 - accuracy: 0.8961 - val_loss: 0.4362 - val_accuracy: 0.8110\n",
            "Epoch 91/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2360 - accuracy: 0.8996 - val_loss: 0.4146 - val_accuracy: 0.8280\n",
            "Epoch 92/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2284 - accuracy: 0.9022 - val_loss: 0.4122 - val_accuracy: 0.8350\n",
            "Epoch 93/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2284 - accuracy: 0.9004 - val_loss: 0.3991 - val_accuracy: 0.8370\n",
            "Epoch 94/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2348 - accuracy: 0.8986 - val_loss: 0.3893 - val_accuracy: 0.8360\n",
            "Epoch 95/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2295 - accuracy: 0.8993 - val_loss: 0.3953 - val_accuracy: 0.8310\n",
            "Epoch 96/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2230 - accuracy: 0.9015 - val_loss: 0.4276 - val_accuracy: 0.8270\n",
            "Epoch 97/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2255 - accuracy: 0.9036 - val_loss: 0.4047 - val_accuracy: 0.8350\n",
            "Epoch 98/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2257 - accuracy: 0.9011 - val_loss: 0.4485 - val_accuracy: 0.8360\n",
            "Epoch 99/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2239 - accuracy: 0.9030 - val_loss: 0.4182 - val_accuracy: 0.8330\n",
            "Epoch 100/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2237 - accuracy: 0.9046 - val_loss: 0.4194 - val_accuracy: 0.8350\n",
            "Epoch 101/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2272 - accuracy: 0.9041 - val_loss: 0.4307 - val_accuracy: 0.8330\n",
            "Epoch 102/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2223 - accuracy: 0.9062 - val_loss: 0.4223 - val_accuracy: 0.8370\n",
            "Epoch 103/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2188 - accuracy: 0.9079 - val_loss: 0.4596 - val_accuracy: 0.8400\n",
            "Epoch 104/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2171 - accuracy: 0.9074 - val_loss: 0.4392 - val_accuracy: 0.8380\n",
            "Epoch 105/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2170 - accuracy: 0.9054 - val_loss: 0.4120 - val_accuracy: 0.8340\n",
            "Epoch 106/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2149 - accuracy: 0.9077 - val_loss: 0.4313 - val_accuracy: 0.8370\n",
            "Epoch 107/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2142 - accuracy: 0.9070 - val_loss: 0.4247 - val_accuracy: 0.8350\n",
            "Epoch 108/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2158 - accuracy: 0.9082 - val_loss: 0.4177 - val_accuracy: 0.8370\n",
            "Epoch 109/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2191 - accuracy: 0.9029 - val_loss: 0.4189 - val_accuracy: 0.8360\n",
            "Epoch 110/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2128 - accuracy: 0.9070 - val_loss: 0.4351 - val_accuracy: 0.8410\n",
            "Epoch 111/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2119 - accuracy: 0.9070 - val_loss: 0.4368 - val_accuracy: 0.8310\n",
            "Epoch 112/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2141 - accuracy: 0.9057 - val_loss: 0.4510 - val_accuracy: 0.8390\n",
            "Epoch 113/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2031 - accuracy: 0.9122 - val_loss: 0.4229 - val_accuracy: 0.8380\n",
            "Epoch 114/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2043 - accuracy: 0.9109 - val_loss: 0.4518 - val_accuracy: 0.8410\n",
            "Epoch 115/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2099 - accuracy: 0.9089 - val_loss: 0.4632 - val_accuracy: 0.8290\n",
            "Epoch 116/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2077 - accuracy: 0.9130 - val_loss: 0.4758 - val_accuracy: 0.8320\n",
            "Epoch 117/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2012 - accuracy: 0.9128 - val_loss: 0.4379 - val_accuracy: 0.8350\n",
            "Epoch 118/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2065 - accuracy: 0.9131 - val_loss: 0.4406 - val_accuracy: 0.8360\n",
            "Epoch 119/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2060 - accuracy: 0.9128 - val_loss: 0.4636 - val_accuracy: 0.8330\n",
            "Epoch 120/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2026 - accuracy: 0.9158 - val_loss: 0.4528 - val_accuracy: 0.8270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4I_icScOVou"
      },
      "source": [
        "#### Saving model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpEQtoH6OaOR",
        "outputId": "e204229b-6603-4e17-d71d-eeea7f79388d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "filename = 'chatbot_120_epochs.h5'\n",
        "model.save(filename)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp24V9oVNtGC"
      },
      "source": [
        "## Evaluating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5gs9ByBN3a1"
      },
      "source": [
        "Ploting out training History"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8UDmgTvN8a4",
        "outputId": "4018fd88-b2fb-48cb-e224-62ddc385d1f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIwCWK_LN-1R"
      },
      "source": [
        "Evaluate on givent test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmzg05FLOEl0"
      },
      "source": [
        "model.load_weights(filename)\n",
        "pred_results = model.predict(([inputs_test, queries_test]))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZA1k4ObOfm2",
        "outputId": "66bcdb23-261f-4a7f-9662-8a3ac648d34e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_data[0][0]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mary',\n",
              " 'got',\n",
              " 'the',\n",
              " 'milk',\n",
              " 'there',\n",
              " '.',\n",
              " 'John',\n",
              " 'moved',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bedroom',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EII3YMrEOgjg",
        "outputId": "147db62e-e5a5-42e9-d61f-3a286c6434a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tory =' '.join(word for word in test_data[0][0])\n",
        "print(story)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Daniel', 'went', 'to', 'the', 'office', '.', 'Sandra', 'journeyed', 'to', 'the', 'hallway', '.', 'Daniel', 'went', 'back', 'to', 'the', 'bedroom', '.', 'Mary', 'got', 'the', 'apple', 'there', '.', 'Sandra', 'moved', 'to', 'the', 'bathroom', '.', 'Mary', 'journeyed', 'to', 'the', 'bedroom', '.', 'Mary', 'put', 'down', 'the', 'apple', 'there', '.', 'Sandra', 'got', 'the', 'milk', 'there', '.', 'Sandra', 'travelled', 'to', 'the', 'bedroom', '.', 'Sandra', 'took', 'the', 'apple', 'there', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqyeNfy1Oiys",
        "outputId": "e09b2112-7d01-461a-8956-c7f0ade92622",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "query = ' '.join(word for word in test_data[0][1])\n",
        "print(query)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is John in the kitchen ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sMI5RznOkE9",
        "outputId": "2e2ef0fd-df1a-4449-845f-def96eed7714",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"True Test Answer from Data is:\",test_data[0][2])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Test Answer from Data is: no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEybzntTOlJd",
        "outputId": "9cee3e5c-0dc8-467c-eb34-5826a288eb6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer is:  no\n",
            "Probability of certainty was:  0.99999166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia-x2S0fOnOg"
      },
      "source": [
        "# Using my own story and Question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOLgvee9OzdL",
        "outputId": "d0f28df4-17ea-4240-9608-9b6bc03cb296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37Bgb7MJSsJp",
        "outputId": "654de697-daf9-488d-c67a-ebef48cb24bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
        "my_story.split()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John',\n",
              " 'left',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'dropped',\n",
              " 'the',\n",
              " 'football',\n",
              " 'in',\n",
              " 'the',\n",
              " 'garden',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsRzLWT8S0KB"
      },
      "source": [
        "my_question = \"Is the football in the garden ?\"\n",
        "my_question.split()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMrDv3CqS307"
      },
      "source": [
        "mydata = [(my_story.split(),my_question.split(),\"yes\")]"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdj5SWJnTF5H"
      },
      "source": [
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3nrfOFETIG3"
      },
      "source": [
        "pred_results = model.predict(([ my_story, my_ques]))"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSH8GPjATORO",
        "outputId": "a9bd59da-e036-440a-b3fd-77f2847b17d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer is:  yes\n",
            "Probability of certainty was:  0.9971539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB2B4B9QTQdl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}