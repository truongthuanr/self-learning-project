{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGbmsZFuOAkjed5Xjz6TzJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/truongthuanr/self-project/blob/dev/11_Named_Entity_Recognition/Named_Entity_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GQ4EHIZSuKoy"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%capture\n",
        "!pip3 install datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from datasets import load_dataset\n",
        "import os\n"
      ],
      "metadata": {
        "id": "77nCH9814O5t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input,Embedding,TimeDistributed,\\\n",
        "                         Dropout,Conv1D,MaxPooling1D,\\\n",
        "                         Flatten,Bidirectional,LSTM,Dense,\\\n",
        "                         concatenate\n",
        "\n",
        "from keras.initializers import RandomUniform\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RiTU7d_YHfc9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "sxvsybnTHfi4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used dataset:\n",
        "\n",
        "https://huggingface.co/datasets/conll2003"
      ],
      "metadata": {
        "id": "jV1nsHAAHo_L"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ip7qnxDkHpnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conll_data = load_dataset(\"conll2003\")"
      ],
      "metadata": {
        "id": "MSK4n-lEHfsw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(conll_data['train']['tokens'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FWXcHbqJaGH",
        "outputId": "ce93cd36-f248-46a9-f726-e3be72e336a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v4xeBd3WHqEA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def export_to_file(export_file_path, data):\n",
        "    with open(export_file_path, \"w\") as f:\n",
        "        for record in data:\n",
        "            ner_tags = record[\"ner_tags\"]\n",
        "            tokens = record[\"tokens\"]\n",
        "            if len(tokens) > 0:\n",
        "                f.write(\n",
        "                    str(len(tokens))\n",
        "                    + \"\\t\"\n",
        "                    + \"\\t\".join(tokens)\n",
        "                    + \"\\t\"\n",
        "                    + \"\\t\".join(map(str, ner_tags))\n",
        "                    + \"\\n\"\n",
        "                )\n",
        "\n",
        "\n",
        "os.mkdir(\"data\")\n",
        "export_to_file(\"./data/conll_train.txt\", conll_data[\"train\"])\n",
        "export_to_file(\"./data/conll_val.txt\", conll_data[\"validation\"])"
      ],
      "metadata": {
        "id": "3wJSzqDjHqLA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing\n"
      ],
      "metadata": {
        "id": "XGNsJro-pu9E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "koLZZUqEpuuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "wordEmbeddings = []\n",
        "caseEmbeddings = []"
      ],
      "metadata": {
        "id": "z1-uPMmlHqP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HWay6MeGHqUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CygvyVy9HqYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "d0235Xcz4fcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "\n"
      ],
      "metadata": {
        "id": "Tn49s6gYmUGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HQQ5xyyOoIcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Work level\n",
        "words_input = Input(shape=(None,),dtype='int32',name='words_input')\n",
        "words = Embedding(input_dim=wordEmbeddings.shape[0], output_dim=wordEmbeddings.shape[1],  weights=[wordEmbeddings], trainable=False)(words_input)\n",
        "\n",
        "casing_input = Input(shape=(None,), dtype='int32', name='casing_input')\n",
        "casing = Embedding(output_dim=caseEmbeddings.shape[1], input_dim=caseEmbeddings.shape[0], weights=[caseEmbeddings], trainable=False)(casing_input)\n",
        "\n",
        "# Character level\n",
        "character_input=Input(shape=(None,52,),name='char_input')\n",
        "embed_char_out=TimeDistributed(Embedding(len(char2Idx),30,embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(character_input)\n",
        "dropout= Dropout(0.5)(embed_char_out)\n",
        "conv1d_out= TimeDistributed(Conv1D(kernel_size=3, filters=30, padding='same',activation='tanh', strides=1))(dropout)\n",
        "maxpool_out=TimeDistributed(MaxPooling1D(52))(conv1d_out)\n",
        "char = TimeDistributed(Flatten())(maxpool_out)\n",
        "char = Dropout(0.5)(char)\n",
        "\n",
        "\n",
        "\n",
        "output = concatenate([words, casing,char])\n",
        "output = Bidirectional(LSTM(200, return_sequences=True, dropout=0.50, recurrent_dropout=0.25))(output)\n",
        "output = TimeDistributed(Dense(len(label2Idx), activation='softmax'))(output)\n",
        "\n",
        "model = Model(inputs=[words_input, casing_input,character_input], outputs=[output])\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam')\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "6nNBmDl2GRf0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hWHebSM7HKdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iaXHRDfQHOi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w7JXMu2OHO64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0COSJnDiHPTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NmowfD8zHPh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JGFfbP-_HPy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YYUZwW6_HP-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References"
      ],
      "metadata": {
        "id": "EvJmuiIiHQJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://keras.io/examples/nlp/ner_transformers/"
      ],
      "metadata": {
        "id": "by174qhpHT_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "urASKXuLHZSz"
      }
    }
  ]
}