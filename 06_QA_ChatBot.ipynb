{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_QA_ChatBot.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/truongthuanr/self-project/blob/main/06_QA_ChatBot.ipynb",
      "authorship_tag": "ABX9TyN6g3wfOO6vTH+RVsQO1DRt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/truongthuanr/self-project/blob/main/06_QA_ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmqEJ03IWNW6"
      },
      "source": [
        "# Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26q629jLUKIr"
      },
      "source": [
        "Reference: \n",
        "* [End-To-End Memory Networks](https://arxiv.org/pdf/1503.08895.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1Ie4ox6WO1C"
      },
      "source": [
        "# import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbZ3fB8Eze0q"
      },
      "source": [
        "import numpy as np\n",
        "import pickle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvLzr8HZy1oO"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/01_Personal/01_Study/01_ML/04_QAChatBot/train_qa.txt\", \"rb\") as f:\n",
        "  train_data = pickle.load(f)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/01_Personal/01_Study/01_ML/04_QAChatBot/test_qa.txt\", \"rb\") as f:\n",
        "  test_data = pickle.load(f)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGdecLspH5Dg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "678a29f9-442d-4397-9742-9ba11117f1b0"
      },
      "source": [
        "print(train_data[506][0])\n",
        "print(train_data[506][1])\n",
        "print(train_data[506][2])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Daniel', 'took', 'the', 'milk', 'there', '.', 'Sandra', 'journeyed', 'to', 'the', 'bedroom', '.', 'Daniel', 'discarded', 'the', 'milk', '.', 'Mary', 'went', 'to', 'the', 'bathroom', '.']\n",
            "['Is', 'Mary', 'in', 'the', 'bathroom', '?']\n",
            "yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MtCkceaGfSl"
      },
      "source": [
        "all_data = train_data + test_data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF42gtM0zbNb",
        "outputId": "58db46f3-3d02-4923-fe42-63c843a66024"
      },
      "source": [
        "len(train_data), len(test_data), len(all_data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1000, 11000)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyZ8yMJdFvIr"
      },
      "source": [
        "vocab = set()\n",
        "\n",
        "for story, question, answer in all_data:\n",
        "  vocab = vocab.union(set(story))\n",
        "  vocab = vocab.union(set(question))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0G5eNaXHb9S"
      },
      "source": [
        "vocab.add('no')\n",
        "vocab.add('yes')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RZVspeHHnnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89023cb1-1f11-41d5-fdda-9835256bc6bb"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH8_3aSYLPck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc9e8ad1-eb26-4914-d2c9-1a081f4e040e"
      },
      "source": [
        "vocab"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWxdyf9UHo0C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb1be9d1-5bc6-41d8-80b4-00bdfd616a45"
      },
      "source": [
        "all_story_lens = [len(data[0]) for data in all_data]\n",
        "max_story_len = max(all_story_lens)\n",
        "max_story_len"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AWrOI-iIzhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ecf4957-aa86-4566-b7d3-cac1e91a118f"
      },
      "source": [
        "all_ques_lens = [len(data[1]) for data in all_data]\n",
        "max_ques_len = max(all_ques_lens)\n",
        "max_ques_len"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4qAJZ3NJDm_"
      },
      "source": [
        "# Vetorize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ikI4FAtJIPr"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI3DQuvKJg6M"
      },
      "source": [
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlsSrdl7JpGV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1109a57a-40ea-46cc-f13b-62fc82d8204b"
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 34,\n",
              " '?': 18,\n",
              " 'apple': 11,\n",
              " 'back': 20,\n",
              " 'bathroom': 10,\n",
              " 'bedroom': 12,\n",
              " 'daniel': 6,\n",
              " 'discarded': 33,\n",
              " 'down': 32,\n",
              " 'dropped': 30,\n",
              " 'football': 7,\n",
              " 'garden': 29,\n",
              " 'got': 22,\n",
              " 'grabbed': 26,\n",
              " 'hallway': 36,\n",
              " 'in': 4,\n",
              " 'is': 14,\n",
              " 'john': 25,\n",
              " 'journeyed': 16,\n",
              " 'kitchen': 2,\n",
              " 'left': 27,\n",
              " 'mary': 24,\n",
              " 'milk': 8,\n",
              " 'moved': 19,\n",
              " 'no': 37,\n",
              " 'office': 17,\n",
              " 'picked': 1,\n",
              " 'put': 13,\n",
              " 'sandra': 5,\n",
              " 'the': 3,\n",
              " 'there': 21,\n",
              " 'to': 35,\n",
              " 'took': 15,\n",
              " 'travelled': 23,\n",
              " 'up': 28,\n",
              " 'went': 9,\n",
              " 'yes': 31}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t858S3jpKAin"
      },
      "source": [
        "train_story_text = []\n",
        "train_ques_text = []\n",
        "train_ans_text = []"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1vF5Wd6KHul"
      },
      "source": [
        "for story,ques,ans in train_data:\n",
        "  train_story_text.append(story)\n",
        "  train_ques_text.append(ques)\n",
        "  train_ans_text.append(ans)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhgKoQ9xKzCq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0361403-8b2a-478f-bc00-3722b302c368"
      },
      "source": [
        "train_story_text[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mary',\n",
              " 'moved',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bathroom',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'journeyed',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bedroom',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3_Kk60JKX85"
      },
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxGBRD0NK-pd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c237422-4b20-4074-d46a-5d5e0b623f9b"
      },
      "source": [
        "len(train_story_seq)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJe53E24KwnL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6192b101-afba-481f-d1a8-25b023e1506f"
      },
      "source": [
        "train_story_seq[0]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[24, 19, 35, 3, 10, 34, 5, 16, 35, 3, 12, 34]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxIOp5PYnxF3"
      },
      "source": [
        "# Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gW4dCkMKylP"
      },
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_ques_len):\n",
        "  '''\n",
        "  INPUT: \n",
        "  \n",
        "  data: consisting of Stories,Queries,and Answers\n",
        "  word_index: word index dictionary from tokenizer\n",
        "  max_story_len: the length of the longest story (used for pad_sequences function)\n",
        "  max_question_len: length of the longest question (used for pad_sequences function)\n",
        "\n",
        "\n",
        "  OUTPUT:\n",
        "  \n",
        "  Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
        "  answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
        "  output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
        "  \n",
        "  Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
        "  '''\n",
        "  \n",
        "  \n",
        "  # X = STORIES\n",
        "  X = []\n",
        "  # Xq = QUERY/QUESTION\n",
        "  Xq = []\n",
        "  # Y = CORRECT ANSWER\n",
        "  Y = []\n",
        "  \n",
        "  \n",
        "  for story, query, answer in data:\n",
        "      \n",
        "      # Grab the word index for every word in story\n",
        "      x = [word_index[word.lower()] for word in story]\n",
        "      # Grab the word index for every word in query\n",
        "      xq = [word_index[word.lower()] for word in query]\n",
        "      \n",
        "      # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
        "      # Index 0 is reserved so we're going to use + 1\n",
        "      y = np.zeros(len(word_index) + 1)\n",
        "      \n",
        "      # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
        "      #\n",
        "      y[word_index[answer]] = 1\n",
        "      \n",
        "      # Append each set of story,query, and answer to their respective holding lists\n",
        "      X.append(x)\n",
        "      Xq.append(xq)\n",
        "      Y.append(y)\n",
        "      \n",
        "  # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
        "      \n",
        "  # RETURN TUPLE FOR UNPACKING\n",
        "  return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFNF5hAanpHJ"
      },
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAyTv0hlGN6u"
      },
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-ApQ8LfGkPT",
        "outputId": "47d111de-5532-4588-87d7-95f82c59642e"
      },
      "source": [
        "inputs_test[0]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0, 24, 22,  3,  8, 21, 34, 25, 19, 35,\n",
              "        3, 12, 34], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_eTX9BhG-iH",
        "outputId": "a0f65f11-42fc-4451-e148-c32129f61acc"
      },
      "source": [
        "inputs_train"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  3, 12, 34],\n",
              "       [ 0,  0,  0, ...,  3, 36, 34],\n",
              "       [ 0,  0,  0, ...,  3, 10, 34],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ...,  3, 12, 34],\n",
              "       [ 0,  0,  0, ...,  8, 21, 34],\n",
              "       [ 0,  0,  0, ..., 11, 21, 34]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgd0Lo6HI6Lw",
        "outputId": "4ad3734f-9e3d-4fdc-efd7-9d7aeb10a3b0"
      },
      "source": [
        "inputs_train.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 156)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3emtR1SH2Zw",
        "outputId": "cf02320d-0453-40a9-9338-bf704f75a8f9"
      },
      "source": [
        "answers_test"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsmeNfUxH3bB",
        "outputId": "fc8dcd00-adfe-43b4-c723-775722477d42"
      },
      "source": [
        "answers_test.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoKbiTaYJAAq"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from keras.layers import add, dot, concatenate\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQZI5ud9JvPU"
      },
      "source": [
        "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs7W9_VEKBzN"
      },
      "source": [
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_ques_len,))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TG4P1MQKEgN"
      },
      "source": [
        "vocab_size = len(vocab) + 1"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRJyHJA5NtPF"
      },
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAFcFmV2Nz-t",
        "outputId": "dab77bd5-57d5-4332-f910-5caf8734c7bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "(samples, story_maxlen, embedding_dim)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-f55f523b4a52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstory_maxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'samples' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DkGhGlBN5C4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}